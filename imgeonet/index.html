<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="ImGeoNet: Image-induced Geometry-aware Voxel Representation for Multi-view 3D Object Detection.">
  <meta name="keywords" content="ImGeoNet, 3D object detection, multiview, image-based object detection">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ImGeoNet: Image-induced Geometry-aware Voxel Representation for Multi-view 3D Object Detection</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <!-- <script src="./static/js/index.js"></script> -->
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://ttaoretw.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">ImGeoNet: Image-induced Geometry-aware Voxel Representation for Multi-view 3D Object Detection</h1>
          <h2 class="title is-size-3 publication-title">ICCV'23</h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ttaoretw.github.io">Tao Tu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/shunpo">Shun-Po Chuang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://yulunalexliu.github.io">Yu-Lun Liu</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://sunset1995.github.io">Cheng Sun</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Ke Zhang</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="">Donna Roy</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="">Cheng-Hao Kuo</a><sup>4</sup>
            </span>
            <span class="author-block">
              <a href="https://aliensunmin.github.io">Min Sun</a><sup>1,4</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>National Tsing Hua University,</span>
            <span class="author-block"><sup>2</sup>National Taiwan University,</span>
            <span class="author-block"><sup>3</sup>National Yang Ming Chiao Tung University,</span>
            <span class="author-block"><sup>4</sup>Amazon</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2308.09098"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ttaoREtw/ImGeoNet"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <center><img src="./static/images/intro.gif" width="70%"></center>
        <div class="content has-text-justified">
          <br>
          <p>
            In contrast to prior works that disregard the underlying geometry by directly averaging feature volume across multiple views,
            our proposed successfully preserves the <strong>geometric structure</strong> with respect to the ground truth while effectively reducing the number of voxels in free space.
            This geometry-aware voxel representation significantly improves 3D object detection performance.
          </p>
        </div>
      </div>
    </div>
  </div>
  <br>

  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We propose ImGeoNet, a multi-view image-based 3D object detection framework that models a 3D space by an image-induced geometry-aware voxel representation.
            Unlike previous methods which aggregate 2D features into 3D voxels without considering geometry, ImGeoNet learns to induce geometry from multi-view images to alleviate the confusion arising from voxels of free space, and during the inference phase, only images from multiple views are required.
            Besides, a powerful pre-trained 2D feature extractor can be leveraged by our representation, leading to a more robust performance.
          </p>
          <p>
            To evaluate the effectiveness of ImGeoNet, we conduct quantitative and qualitative experiments on three indoor datasets, namely ARKitScenes, ScanNetV2, and ScanNet200.
            The results demonstrate that ImGeoNet outperforms the current state-of-the-art multi-view image-based method, ImVoxelNet, on all three datasets in terms of detection accuracy.
            In addition, ImGeoNet shows great data efficiency by achieving results comparable to ImVoxelNet with 100 views while utilizing only 40 views.
            Furthermore, our studies indicate that our proposed image-induced geometry-aware representation can enable image-based methods to attain superior detection accuracy than the seminal point cloud-based method, VoteNet, in two practical scenarios: (1) scenarios where point clouds are sparse and noisy, such as in ARKitScenes, and (2) scenarios involve diverse object classes, particularly classes of small objects, as in the case in ScanNet200.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Overview. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">ImGeoNet</h2>
        <center><img src="./static/images/overview.png"></center>
        <div class="content has-text-justified">
          <br>
          <p>
            Given an arbitrary number of images, a 2D convolution backbone (Conv2D) is applied to extract visual features from each image, and then a 3D voxel feature volume is constructed by back-projecting and accumulating 2D features to the volume.
            This feature volume is not ideal since the underlying geometry of the scene is not considered.
            Hence, the proposed geometry shaping is applied to weight the original feature volume by the predicted surface probabilities, which preserves the geometric structure and removes voxels of free space.
            Finally, the geometry-aware volume is passed to the multiscale 3D convolutional layers (M3DConv) and the detection head.
          </p>
        </div>
      </div>
    </div>

    <!-- Result. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Quantitative Results</h2>
        <div class="table_wrapper">
          <table class="table is-hoverable is-bordered">
            <thead>
              <tr>
                <th scope="col" style="vertical-align:middle;text-align:center;" rowspan="2">Method</th>
                <th scope="col" style="vertical-align:middle;text-align:center;" rowspan="2">Input</th>
                <th scope="col" colspan="2">(1) Noisy & sparse &#9729;&#65039;</th>
                <th scope="col" colspan="1">(2) Diverse objects &#129327;</th>
                <th scope="col" colspan="2">(3) Benchmark &#9878;&#65039;</th>
              </tr>
              <tr>
                <th scope="col">mAP@0.25</th>
                <th scope="col">mAP@0.5</th>
                <th scope="col">mAP@0.25</th>
                <th scope="col">mAP@0.25</th>
                <th scope="col">mAP@0.5</th>
              </tr>
            </thead>
            <tr color="red">
              <td scope="col" style="text-align:left"><span class="highlight">ImGeoNet</span></td>
              <td scope="col">RGB</td>
              <td scope="col"><span class="highlight">60.2</span></td>
              <td scope="col"><span class="highlight">43.4</span></td>
              <td scope="col"><span class="highlight">22.3</span></td>
              <td scope="col">54.8</td>
              <td scope="col">28.4</td>
            </tr>
            <tr>
              <td scope="col" style="text-align:left">ImVoxelNet</td>
              <td scope="col">RGB</td>
              <td scope="col">58.0</td>
              <td scope="col">38.8</td>
              <td scope="col">19.0</td>
              <td scope="col">48.7</td>
              <td scope="col">23.8</td>
            </tr>
            <tr>
              <td scope="col" style="text-align:left">VoteNet</td>
              <td scope="col">Point cloud (costly!!)</td>
              <td scope="col">53.3</td>
              <td scope="col">38.5</td>
              <td scope="col">19.8</td>
              <td scope="col"><span class="highlight">58.6</span></td>
              <td scope="col"><span class="highlight">33.5</span></td>
            </tr>
          </table>
        </div>
        <div class="content has-text-justified">
          <p>
            In practical situations, (1) depth images often exhibit noise and sparsity, as seen in ARKitScenes, and (2) objects can display considerable variation, as exemplified by ScanNet200.
            We demonstrate that ImGeoNet surpasses prior techniques in addressing these real-world conditions.
            (3) Lastly, we evaluate ImGeoNet against previous approaches using the standardized ScanNet benchmark, comprising superior depth images and point clouds.
            Although VoteNet exhibits superior accuracy in this case, it's worth noting that point cloud-based methods are constrained by reliance on expensive 3D sensor data.
          </p>
        </div>
      </div>
    </div>
    <!-- Result. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Qualitative Results</h2>
        <center><img src="./static/images/visualization.jpg" width="100%"></center>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{tu2023imgeonet,
  title     = {ImGeoNet: Image-induced Geometry-aware Voxel Representation for Multi-view 3D Object Detection},
  author    = {Tu, Tao and Chuang, Shun-Po and Liu, Yu-Lun and Sun, Cheng and Zhang, Ke and Roy, Donna and Kuo, Cheng-Hao and Sun, Min},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  year      = {2023},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This webpage template is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0 License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
